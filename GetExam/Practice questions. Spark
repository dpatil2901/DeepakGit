from pyspark.sql import SparkSession

# Create a Spark session
spark = SparkSession.builder.appName("OrderAnalysis").getOrCreate()

# Assuming you have the data in a list
data = [
    (70001, 150.5, "2012-10-05", 3005, 5002),
    (70009, 270.65, "2012-09-10", 3001, 5005),
    (70002, 65.26, "2012-10-05", 3002, 5001),
    (70004, 110.5, "2012-08-17", 3009, 5003),
    (70007, 948.5, "2012-09-10", 3005, 5002),
    (70005, 2400.6, "2012-07-27", 3007, 5001),
    (70008, 5760, "2012-09-10", 3002, 5001),
    (70010, 1983.43, "2012-10-10", 3004, 5006),
    (70003, 2480.4, "2012-10-10", 3009, 5003),
    (70012, 250.45, "2012-06-27", 3008, 5002),
    (70011, 75.29, "2012-08-17", 3003, 5007),
    (70013, 3045.6, "2012-04-25", 3002, 5001)
]

columns = ["ord_no", "purch_amt", "ord_date", "customer_id", "salesman_id"]

# Create DataFrame
order_df = spark.createDataFrame(data, columns)

# Display DataFrame
order_df.show()


Aggregation Questions:

Question 1:
Calculate the total purchase amount for each salesman.

Question 2:
Find the average purchase amount for each month.

Question 3:
Determine the maximum purchase amount and the corresponding order number.

Question 4:
Calculate the total purchase amount for each customer.

Question 5:
Find the minimum and maximum order dates.
Question 6:
Calculate the average purchase amount for each salesman.

Question 7:
Determine the total purchase amount and the average purchase amount for each customer.

Question 8:
Identify the salesman with the highest total purchase amount.

Question 9:
Calculate the total purchase amount for each month.

Question 10:
Find the average purchase amount and the total number of orders for each salesman.
